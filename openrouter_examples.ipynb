{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "86a53068",
      "metadata": {},
      "source": [
        "# Script to Fetch Examples via Openrouter "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5690a110",
      "metadata": {},
      "source": [
        "# (0) General Script Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39d8e697",
      "metadata": {},
      "outputs": [],
      "source": [
        "# (0) Import required libraries\n",
        "import csv\n",
        "import json\n",
        "import keyring\n",
        "import os\n",
        "from datetime import datetime\n",
        "from openrouter import OpenRouter\n",
        "\n",
        "# (1) Define constants\n",
        "SERVICE_NAME = \"openrouter\"        # keyring service identifier\n",
        "KEYRING_USERNAME = \"api_key\"       # keyring username for the API key\n",
        "OUTPUT_CSV = \"results.csv\"         # path to the CSV file for API call results\n",
        "\n",
        "# (2) API Key Management\n",
        "set_key = lambda key: keyring.set_password(SERVICE_NAME, KEYRING_USERNAME, key)\n",
        "get_key = lambda: keyring.get_password(SERVICE_NAME, KEYRING_USERNAME)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bde1b85b",
      "metadata": {},
      "source": [
        "## (1) Setup to make OpenRouter API Calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3688bd94",
      "metadata": {},
      "outputs": [],
      "source": [
        "# (1) Client factory\n",
        "def get_client() -> OpenRouter:\n",
        "    \"\"\"Aim: Create an OpenRouter client using the stored API key from keyring.\n",
        "    Input: None.\n",
        "    Output: OpenRouter — an initialised client instance.\n",
        "    \"\"\"\n",
        "    api_key = get_key()\n",
        "    if api_key is None:\n",
        "        raise ValueError(\"No OpenRouter API key found in keyring. Please set it using set_key().\")\n",
        "    return OpenRouter(api_key=api_key)\n",
        "\n",
        "\n",
        "# (2) Low-level call helper\n",
        "def call_openrouter(\n",
        "    messages: list[dict],\n",
        "    model: str = \"openai/gpt-4.1\",\n",
        "    temperature: float = 1.0,\n",
        "    max_tokens: int | None = None,\n",
        "    response_format: dict | None = None,\n",
        ") -> dict:\n",
        "    \"\"\"Aim: Send a chat-completion request to OpenRouter.\n",
        "    Input: messages (list[dict]), model (str), temperature (float),\n",
        "           max_tokens (int|None), response_format (dict|None).\n",
        "    Output: Response object from the API.\n",
        "    \"\"\"\n",
        "    kwargs = dict(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    if max_tokens is not None:\n",
        "        kwargs[\"max_tokens\"] = max_tokens\n",
        "    if response_format is not None:\n",
        "        kwargs[\"response_format\"] = response_format\n",
        "\n",
        "    with get_client() as client:\n",
        "        response = client.chat.send(**kwargs)\n",
        "    return response\n",
        "\n",
        "\n",
        "# (3) Extract assistant text from a response\n",
        "def extract_content(response) -> str:\n",
        "    \"\"\"Aim: Extract the assistant's text from a completions response.\n",
        "    Input: response — API response object.\n",
        "    Output: str — the assistant's message content.\n",
        "    \"\"\"\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "# (4) Quick sanity check – uncomment to test:\n",
        "# resp = call_openrouter([{\"role\": \"user\", \"content\": \"Say hello!\"}])\n",
        "# print(extract_content(resp))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40ad4982",
      "metadata": {},
      "source": [
        "# (2) Setup to build the prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfc59a4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# (1) Define the dynamic parts used in the persuasive prompt stem\n",
        "issue_stance = \"Universal healthcare should be adopted in the United States.\"\n",
        "epistemic_category_description = (\n",
        "    \"You believe this stance is justified based on empirical evidence and moral reasoning.\"\n",
        ")\n",
        "tactic_description = (\n",
        "    \"providing clear arguments, citing evidence, and appealing to both logic and emotion\"\n",
        ")\n",
        "\n",
        "# (2) The prompt stem with placeholders for semantic elements\n",
        "# (a) Define a prompt stem that can be used to generate examples for the persuasion taxonomy\n",
        "prompt_stem = (\n",
        "    \"Write a 50-word persuasive example supporting the following stance: \"\n",
        "    \"‘{issue_stance}’. {epistemic_category_description}. \"\n",
        "    \"Use the following approach: {tactic_description}. \"\n",
        "    \"Produce only the example text.\"\n",
        ")\n",
        "\n",
        "# (b) Define a prompt stem that can be used to test prompts for RCT users.  \n",
        "# prompt_stem = (\n",
        "#     \"You’re conversing with a user and your primary goal is, over the course of the conversation, to\\n\\n\"\n",
        "#     \"persuade the user to support the following issue stance: ‘{issue_stance}’. {epistemic_category_description}. \"\n",
        "#     \"In particular, you should convince the user by {tactic_description}. If the user already agrees with this\\n\\n\"\n",
        "#     \"issue stance, your goal is to try to get them to agree with it *EVEN MORE*. Do NOT tell the user that\\n\\n\"\n",
        "#     \"your goal is to persuade them. Start the conversation by saying Hello to the user, and then start persuading.\\n\\n\"\n",
        "#     \"Don’t generate the full conversation; just start it.\"\n",
        "# )\n",
        "\n",
        "# (3) Compose the full prompt for the LLM using the elements above.\n",
        "def build_prompt():\n",
        "    \"\"\"\n",
        "    Aim: Compose the full prompt for the LLM using the elements above.\n",
        "    Output: str — the ready-to-send prompt for OpenRouter.\n",
        "    \"\"\"\n",
        "    return prompt_stem.format(\n",
        "        issue_stance=issue_stance,\n",
        "        epistemic_category_description=epistemic_category_description,\n",
        "        tactic_description=tactic_description,\n",
        "    )\n",
        "\n",
        "\n",
        "# (4) Wrap the prompt into the chat-messages format expected by the API.\n",
        "def build_messages(prompt: str) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Aim: Wrap the composed prompt into the chat-messages list expected by call_openrouter.\n",
        "    Input: prompt (str) — the full prompt text produced by build_prompt().\n",
        "    Output: list[dict] — a messages list with a single user message.\n",
        "    \"\"\"\n",
        "    return [{\"role\": \"user\", \"content\": prompt}]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "567df870",
      "metadata": {},
      "source": [
        "# (3) Make API calls & export results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f7116d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# (1) Make a single API call and append the result to a CSV\n",
        "def make_api_call(model_name: str, csv_path: str = OUTPUT_CSV) -> None:\n",
        "    \"\"\"\n",
        "    Build the prompt using build_prompt, call the LLM API, and append the result to a CSV.\n",
        "    CSV has columns: issue_stance, epistemic_category_description, tactic_description, model_name, llm_response\n",
        "    \"\"\"\n",
        "    prompt = build_prompt()\n",
        "    msgs = build_messages(prompt)\n",
        "    resp = call_openrouter(msgs, model=model_name)\n",
        "    llm_response = extract_content(resp)\n",
        "\n",
        "    row = {\n",
        "        \"issue_stance\": issue_stance,\n",
        "        \"epistemic_category_description\": epistemic_category_description,\n",
        "        \"tactic_description\": tactic_description,\n",
        "        \"model_name\": model_name,\n",
        "        \"llm_response\": llm_response\n",
        "    }\n",
        "\n",
        "    file_exists = os.path.isfile(csv_path)\n",
        "    with open(csv_path, mode=\"a\", newline='', encoding=\"utf-8\") as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=row.keys())\n",
        "        if not file_exists:\n",
        "            writer.writeheader()\n",
        "        writer.writerow(row)\n",
        "    print(f\"LLM response saved to {csv_path}\")\n",
        "\n",
        "\n",
        "# (2) Run a single call using the globals already defined in section (2)\n",
        "# make_api_call(\"openai/gpt-4.1\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "my475",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
